{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37a0e5a2-f82d-4389-84ba-091a9a95a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a79dd71-5609-44d8-9421-654c77bbb187",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('arc-agi_training_challenges.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b153cfa-49e0-43c0-95b8-b1a8260f1419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00576224'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df5df8be-dc19-42f0-838c-c0bdc29517f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [{'input': [[7, 9], [4, 3]],\n",
       "   'output': [[7, 9, 7, 9, 7, 9],\n",
       "    [4, 3, 4, 3, 4, 3],\n",
       "    [9, 7, 9, 7, 9, 7],\n",
       "    [3, 4, 3, 4, 3, 4],\n",
       "    [7, 9, 7, 9, 7, 9],\n",
       "    [4, 3, 4, 3, 4, 3]]},\n",
       "  {'input': [[8, 6], [6, 4]],\n",
       "   'output': [[8, 6, 8, 6, 8, 6],\n",
       "    [6, 4, 6, 4, 6, 4],\n",
       "    [6, 8, 6, 8, 6, 8],\n",
       "    [4, 6, 4, 6, 4, 6],\n",
       "    [8, 6, 8, 6, 8, 6],\n",
       "    [6, 4, 6, 4, 6, 4]]}],\n",
       " 'test': [{'input': [[3, 2], [7, 8]]}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['00576224']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5991a69-0312-4448-aa01-a06efbe1cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_arc_task(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Verify the expected structure\n",
    "        if 'train' not in data or 'test' not in data:\n",
    "            raise ValueError(\"JSON file doesn't have the expected 'train' and 'test' keys\")\n",
    "            \n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return None\n",
    "\n",
    "def display_grids(data):\n",
    "    \"\"\"\n",
    "    Display the input and output grids in a more readable format.\n",
    "    \n",
    "    Parameters:\n",
    "    data (dict): Dictionary containing the ARC task data\n",
    "    \"\"\"\n",
    "    print(\"TRAINING EXAMPLES:\")\n",
    "    for i, example in enumerate(data['train']):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(\"Input:\")\n",
    "        for row in example['input']:\n",
    "            print(row)\n",
    "        print(\"Output:\")\n",
    "        for row in example['output']:\n",
    "            print(row)\n",
    "    \n",
    "    print(\"\\nTEST EXAMPLES:\")\n",
    "    for i, example in enumerate(data['test']):\n",
    "        print(f\"\\nTest {i+1}:\")\n",
    "        print(\"Input:\")\n",
    "        for row in example['input']:\n",
    "            print(row)\n",
    "        if 'output' in example:  # Output may not be available for test data\n",
    "            print(\"Output:\")\n",
    "            for row in example['output']:\n",
    "                print(row)\n",
    "\n",
    "def extract_test_inputs(data):\n",
    "    \"\"\"\n",
    "    Extract only the test input grids from the data.\n",
    "    \n",
    "    Parameters:\n",
    "    data (dict): Dictionary containing the ARC task data\n",
    "    \n",
    "    Returns:\n",
    "    list: List of test input grids\n",
    "    \"\"\"\n",
    "    return [example['input'] for example in data['test']]\n",
    "\n",
    "def extract_train_pairs(data):\n",
    "    \"\"\"\n",
    "    Extract all training input-output pairs as separate lists.\n",
    "    \n",
    "    Parameters:\n",
    "    data (dict): Dictionary containing the ARC task data\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (list of training inputs, list of training outputs)\n",
    "    \"\"\"\n",
    "    train_inputs = [example['input'] for example in data['train']]\n",
    "    train_outputs = [example['output'] for example in data['train']]\n",
    "    return train_inputs, train_outputs\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual file path\n",
    "    file_path = \"path/to/arc_task.json\"\n",
    "    \n",
    "    # Read the task data\n",
    "    task_data = read_arc_task(file_path)\n",
    "    \n",
    "    if task_data:\n",
    "        # Display the grids\n",
    "        display_grids(task_data)\n",
    "        \n",
    "        # Extract just the training pairs\n",
    "        train_inputs, train_outputs = extract_train_pairs(task_data)\n",
    "        print(\"\\nExtracted training inputs:\", train_inputs)\n",
    "        \n",
    "        # Extract just the test inputs\n",
    "        test_inputs = extract_test_inputs(task_data)\n",
    "        print(\"\\nExtracted test inputs:\", test_inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
